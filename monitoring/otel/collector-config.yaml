receivers:
  otlp:
    protocols:
      grpc:
        endpoint: 0.0.0.0:4317
      http:
        endpoint: 0.0.0.0:4318
        cors:
          allowed_origins:
            - "http://localhost:3001"
            - "https://atlas-debate.com"

  # Prometheus receiver for scraping metrics
  prometheus:
    config:
      scrape_configs:
        - job_name: 'atlas-debate'
          scrape_interval: 30s
          static_configs:
            - targets: ['atlas-debate:3001']
              labels:
                service: 'atlas-debate'
                environment: '${ENVIRONMENT}'

  # Host metrics
  hostmetrics:
    collection_interval: 30s
    scrapers:
      cpu:
      memory:
      disk:
      network:
      load:

processors:
  # Add metadata
  resource:
    attributes:
      - key: service.name
        value: atlas-debate
        action: upsert
      - key: deployment.environment
        value: ${ENVIRONMENT}
        action: upsert
      - key: service.version
        value: ${SERVICE_VERSION}
        action: upsert

  # Batch processing for efficiency
  batch:
    timeout: 10s
    send_batch_size: 1024

  # Memory limiter to prevent OOM
  memory_limiter:
    check_interval: 1s
    limit_mib: 512
    spike_limit_mib: 128

  # Filter out noisy traces
  filter/traces:
    error_mode: ignore
    traces:
      span:
        - 'attributes["http.route"] == "/api/health"'
        - 'attributes["http.route"] == "/api/monitoring/health"'

  # Add span metrics
  spanmetrics:
    metrics_exporter: prometheus
    latency_histogram_buckets: [5ms, 10ms, 25ms, 50ms, 100ms, 250ms, 500ms, 1s, 2s, 5s]
    dimensions:
      - name: http.method
      - name: http.status_code
      - name: http.route

  # Tail sampling for traces
  tail_sampling:
    decision_wait: 10s
    num_traces: 10000
    expected_new_traces_per_sec: 100
    policies:
      - name: errors-policy
        type: status_code
        status_code: {status_codes: [ERROR]}
      - name: slow-traces-policy
        type: latency
        latency: {threshold_ms: 2000}
      - name: probabilistic-policy
        type: probabilistic
        probabilistic: {sampling_percentage: 10}

exporters:
  # Prometheus exporter
  prometheus:
    endpoint: "0.0.0.0:8888"
    namespace: atlas-debate
    const_labels:
      environment: ${ENVIRONMENT}

  # OTLP exporter (for sending to cloud providers)
  otlp/cloud:
    endpoint: ${OTLP_ENDPOINT}
    headers:
      api-key: ${OTLP_API_KEY}
    compression: gzip
    retry_on_failure:
      enabled: true
      initial_interval: 5s
      max_interval: 30s
      max_elapsed_time: 300s

  # Logging exporter for debugging
  logging:
    loglevel: info
    sampling_initial: 10
    sampling_thereafter: 100

  # File exporter for backup
  file:
    path: /var/log/otel/traces.json
    rotation:
      max_megabytes: 100
      max_days: 7
      max_backups: 3

extensions:
  # Health check
  health_check:
    endpoint: "0.0.0.0:13133"
    path: "/health"

  # Performance profiler
  pprof:
    endpoint: "0.0.0.0:1777"

  # Z-pages for debugging
  zpages:
    endpoint: "0.0.0.0:55679"

service:
  extensions: [health_check, pprof, zpages]
  
  pipelines:
    # Traces pipeline
    traces:
      receivers: [otlp]
      processors: [memory_limiter, resource, filter/traces, batch, tail_sampling]
      exporters: [otlp/cloud, spanmetrics, logging]

    # Metrics pipeline
    metrics:
      receivers: [otlp, prometheus, hostmetrics, spanmetrics]
      processors: [memory_limiter, resource, batch]
      exporters: [prometheus, otlp/cloud]

    # Logs pipeline (if needed)
    logs:
      receivers: [otlp]
      processors: [memory_limiter, resource, batch]
      exporters: [otlp/cloud, file]

  telemetry:
    logs:
      level: info
      development: false
      encoding: json
    metrics:
      level: detailed
      address: 0.0.0.0:8889