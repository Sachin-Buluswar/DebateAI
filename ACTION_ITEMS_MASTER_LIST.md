# ðŸš€ Eris Debate - Complete Master Action Items List

This is your COMPREHENSIVE list of ALL tasks needed to get Eris Debate fully functional and production-ready. Every task is explained in detail.

## âœ… COMPLETED BY AI
- Added rate limiting to all unprotected API routes
- Updated .env.example with all missing environment variables
- Verified CORS is properly configured (uses ALLOWED_ORIGINS env var)
- Verified viewport meta tag is present (uses Next.js 13+ viewport export)
- Verified debug endpoint has proper security (API key + IP allowlist)
- Enabled pg_trgm extension in database via Supabase MCP
- Created REST API fallback endpoints (/api/debate/start, /api/debate/speech, /api/debate/end)
- Fixed socketFallback.ts implementation with proper error handling
- Created debate audio bucket setup script (/scripts/setup-debate-audio-bucket.js)
- Fixed TypeScript compilation errors (removed extra parentheses in function parameters)
- Removed conflicting App Router socketio route (keeping Pages Router version)

## ðŸ”´ CRITICAL - Must Complete First (Blocks Core Functionality)

### 1. Fix ALL Database Issues
**Why**: Multiple core features are completely broken without these tables
**Time**: 45-60 minutes
**Impact**: Search, debates, feedback, and document features won't work

#### A. Create Search System Tables
**Location**: Supabase Dashboard â†’ SQL Editor
**Instructions**:

1. **First, run this SQL to create the search tables**:
```sql
-- Create documents table
CREATE TABLE IF NOT EXISTS documents (
  id UUID DEFAULT gen_random_uuid() PRIMARY KEY,
  title TEXT NOT NULL,
  content TEXT,
  url TEXT,
  category TEXT,
  uploaded_by UUID REFERENCES auth.users(id),
  created_at TIMESTAMP WITH TIME ZONE DEFAULT now(),
  updated_at TIMESTAMP WITH TIME ZONE DEFAULT now()
);

-- Create document_chunks table for search
CREATE TABLE IF NOT EXISTS document_chunks (
  id UUID DEFAULT gen_random_uuid() PRIMARY KEY,
  document_id UUID REFERENCES documents(id) ON DELETE CASCADE,
  content TEXT NOT NULL,
  embedding VECTOR(1536),
  chunk_index INTEGER NOT NULL,
  metadata JSONB DEFAULT '{}',
  created_at TIMESTAMP WITH TIME ZONE DEFAULT now()
);

-- Enable Row Level Security
ALTER TABLE documents ENABLE ROW LEVEL SECURITY;
ALTER TABLE document_chunks ENABLE ROW LEVEL SECURITY;

-- Create RLS policies for documents
CREATE POLICY "Documents are viewable by everyone" ON documents
  FOR SELECT USING (true);

CREATE POLICY "Users can insert their own documents" ON documents
  FOR INSERT WITH CHECK (auth.uid() = uploaded_by);

CREATE POLICY "Users can update their own documents" ON documents
  FOR UPDATE USING (auth.uid() = uploaded_by);

CREATE POLICY "Users can delete their own documents" ON documents
  FOR DELETE USING (auth.uid() = uploaded_by);

-- Create RLS policies for document_chunks
CREATE POLICY "Document chunks are viewable by everyone" ON document_chunks
  FOR SELECT USING (true);

CREATE POLICY "Document chunks follow document permissions" ON document_chunks
  FOR ALL USING (
    EXISTS (
      SELECT 1 FROM documents 
      WHERE documents.id = document_chunks.document_id 
      AND (documents.uploaded_by = auth.uid() OR documents.uploaded_by IS NULL)
    )
  );

-- Create indexes for better search performance
CREATE INDEX idx_documents_title_trgm ON documents USING gin(title gin_trgm_ops);
CREATE INDEX idx_documents_content_trgm ON documents USING gin(content gin_trgm_ops);
CREATE INDEX idx_document_chunks_content_trgm ON document_chunks USING gin(content gin_trgm_ops);
CREATE INDEX idx_document_chunks_embedding ON document_chunks USING ivfflat(embedding vector_cosine_ops);
```

2. **Create the debate-documents storage bucket**:
   - Go to Storage â†’ New Bucket
   - Name: `debate-documents`
   - Public: âœ… Yes (check this box)
   - File size limit: 50MB
   - Allowed MIME types: `application/pdf`
   - Click "Create bucket"

#### B. Fix Debate System Tables
**Why**: The debate feature has conflicting table names and missing tables

1. **Run this SQL to fix the debate system**:
```sql
-- First, check if 'debates' table exists and rename it if needed
DO $$ 
BEGIN
  IF EXISTS (SELECT 1 FROM information_schema.tables WHERE table_name = 'debates') THEN
    ALTER TABLE debates RENAME TO debate_sessions;
  END IF;
END $$;

-- Ensure debate_sessions has all required columns
ALTER TABLE debate_sessions 
ADD COLUMN IF NOT EXISTS has_ai_partner BOOLEAN DEFAULT false,
ADD COLUMN IF NOT EXISTS speech_count INTEGER DEFAULT 0,
ADD COLUMN IF NOT EXISTS last_activity TIMESTAMP WITH TIME ZONE,
ADD COLUMN IF NOT EXISTS user_side TEXT CHECK (user_side IN ('PRO', 'CON')),
ADD COLUMN IF NOT EXISTS winner TEXT CHECK (winner IN ('PRO', 'CON', 'DRAW')),
ADD COLUMN IF NOT EXISTS end_reason TEXT,
ADD COLUMN IF NOT EXISTS user_id UUID REFERENCES auth.users(id);

-- Create speeches table for storing individual speeches
CREATE TABLE IF NOT EXISTS speeches (
  id UUID DEFAULT gen_random_uuid() PRIMARY KEY,
  session_id UUID REFERENCES debate_sessions(id) ON DELETE CASCADE,
  speaker_id UUID NOT NULL,
  content TEXT NOT NULL,
  side TEXT CHECK (side IN ('PRO', 'CON')),
  timestamp TIMESTAMP WITH TIME ZONE DEFAULT now(),
  created_at TIMESTAMP WITH TIME ZONE DEFAULT now()
);

-- Enable RLS
ALTER TABLE speeches ENABLE ROW LEVEL SECURITY;

-- Create RLS policies for speeches
CREATE POLICY "Speeches are viewable by participants" ON speeches
  FOR SELECT USING (
    EXISTS (
      SELECT 1 FROM debate_sessions 
      WHERE debate_sessions.id = speeches.session_id 
      AND debate_sessions.user_id = auth.uid()
    )
  );

CREATE POLICY "Users can insert speeches for their debates" ON speeches
  FOR INSERT WITH CHECK (
    EXISTS (
      SELECT 1 FROM debate_sessions 
      WHERE debate_sessions.id = speeches.session_id 
      AND debate_sessions.user_id = auth.uid()
    )
  );

-- Create indexes
CREATE INDEX idx_speeches_session_id ON speeches(session_id);
CREATE INDEX idx_speeches_timestamp ON speeches(timestamp);
```

#### C. Create User Feedback Table
**Why**: The feedback form component expects this table

```sql
-- Create user_feedback table
CREATE TABLE IF NOT EXISTS user_feedback (
  id UUID DEFAULT gen_random_uuid() PRIMARY KEY,
  user_id UUID REFERENCES auth.users(id),
  feedback_type TEXT NOT NULL,
  message TEXT NOT NULL,
  rating INTEGER CHECK (rating >= 1 AND rating <= 5),
  created_at TIMESTAMP WITH TIME ZONE DEFAULT now()
);

-- Enable RLS
ALTER TABLE user_feedback ENABLE ROW LEVEL SECURITY;

-- Create RLS policies
CREATE POLICY "Users can insert their own feedback" ON user_feedback
  FOR INSERT WITH CHECK (auth.uid() = user_id OR user_id IS NULL);

CREATE POLICY "Users can view their own feedback" ON user_feedback
  FOR SELECT USING (auth.uid() = user_id);
```

3. **Clear PostgREST Cache** (IMPORTANT):
   - Go to Settings â†’ API
   - Click "Reload schema cache"
   - Wait 30 seconds for it to propagate

### 2. Add ALL Missing Environment Variables
**Why**: Several features won't work without these
**Time**: 20 minutes
**Location**: Your `.env.local` file

Add these to your `.env.local` file with actual values:

```env
# CRITICAL - Features won't work without these
ELEVENLABS_CROSSFIRE_AGENT_ID=your-crossfire-agent-id-here  # Get from ElevenLabs dashboard
OPENAI_VECTOR_STORE_ID=your-vector-store-id-here  # Get from OpenAI dashboard

# SQL Endpoint Security (REQUIRED for production)
ENABLE_SQL_ENDPOINT=false  # Keep false in production!
ADMIN_SQL_KEY=generate-a-long-random-string-here  # Use: openssl rand -hex 32

# OpenTelemetry Monitoring (NEW - was missing)
OTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:4318  # Change for production

# Debug Security (REQUIRED)
DEBUG_API_KEY=generate-another-long-random-string-here  # Use: openssl rand -hex 32
DEBUG_ALLOWED_IPS=127.0.0.1  # Add your IP if needed

# Port Configuration (Standardize)
PORT=3001  # Make sure this matches everywhere

# Error Tracking (HIGHLY RECOMMENDED)
SENTRY_DSN=your-sentry-dsn-here
NEXT_PUBLIC_SENTRY_DSN=your-sentry-dsn-here
SENTRY_AUTH_TOKEN=your-sentry-auth-token
SENTRY_ORG=your-org
SENTRY_PROJECT=your-project
ENABLE_SENTRY_DEV=false
NEXT_PUBLIC_ENABLE_SENTRY_DEV=false

# Production Domain
NEXT_PUBLIC_APP_DOMAIN=atlasdebate.com  # Your actual domain
```

**How to get these values**:
- **ELEVENLABS_CROSSFIRE_AGENT_ID**: 
  1. Log into ElevenLabs dashboard
  2. Go to "Agents" or "Conversational AI"
  3. Create or find your crossfire agent
  4. Copy the agent ID

- **OPENAI_VECTOR_STORE_ID**:
  1. Log into OpenAI platform
  2. Go to "Assistants" â†’ "Vector Stores"
  3. Create a new vector store or use existing
  4. Copy the ID (starts with 'vs_')

### 3. Create Debate Audio Storage Bucket
**Why**: Audio recording features will fail without this
**Time**: 5 minutes

**Option A - Run the script**:
```bash
node scripts/setup-debate-audio-bucket.js
```

**Option B - Manual creation**:
1. Go to Supabase Dashboard â†’ Storage
2. Click "New bucket"
3. Settings:
   - Name: `debate_audio`
   - Public: âŒ No (keep private)
   - File size limit: 10MB
   - Allowed MIME types: `audio/mpeg,audio/mp3,audio/wav,audio/webm`
4. Click "Create bucket"

### 4. Fix Critical Security Issues
**Why**: Current configuration has vulnerabilities
**Time**: 15 minutes

#### A. Fix CORS Configuration
**File**: `vercel.json`
**Current Issue**: Using wildcard `*` allows any website to use your API

Change this:
```json
{
  "key": "Access-Control-Allow-Origin",
  "value": "*"
}
```

To this:
```json
{
  "key": "Access-Control-Allow-Origin", 
  "value": "https://atlasdebate.com"
}
```

Or for multiple domains:
```json
{
  "key": "Access-Control-Allow-Origin",
  "value": "https://atlasdebate.com,https://www.atlasdebate.com"
}
```

#### B. Update Socket.IO Configuration
**File**: `src/backend/sockets/socketio.ts`
**Issue**: Hardcoded domains

Find and replace:
- `localhost:3001` â†’ Use `process.env.NEXT_PUBLIC_APP_URL`
- `atlasdebate.com` â†’ Use `process.env.NEXT_PUBLIC_APP_DOMAIN`

## ðŸŸ¡ IMPORTANT - Complete Before Production

### 5. Consolidate Configuration Files
**Why**: Multiple config files cause confusion and potential conflicts
**Time**: 20 minutes

You have these Next.js configs:
- `next.config.mjs` (main)
- `next.config.cjs` 
- `next.config.sentry.js`

**Action**: Merge all into `next.config.mjs` and delete the others

### 6. Fix Port Configuration Inconsistency
**Why**: Some files use port 3001, others use 3003
**Time**: 10 minutes

1. Search for `3003` across the codebase
2. Replace all instances with `3001` or use `process.env.PORT`
3. Ensure package.json scripts all use the same port

### 7. Set Up Error Tracking (Sentry)
**Why**: Essential for debugging production issues
**Time**: 30 minutes

1. Create account at https://sentry.io (free tier is fine)
2. Create a new project (Next.js)
3. Copy the DSN from project settings
4. Add to environment variables (see step 2)
5. Test by throwing an error in development

### 8. Enable Database Connection Pooling
**Why**: Prevents "too many connections" errors under load
**Time**: 5 minutes

1. Go to Supabase Dashboard â†’ Settings â†’ Database
2. Find "Connection Pooling" section
3. Enable it
4. Settings:
   - Pool Mode: Transaction
   - Pool Size: 15 (default)
   - Click "Save"

### 9. Fix Logging (Replace console.log)
**Why**: 701 console.log statements pollute logs and miss important errors
**Time**: 1-2 hours

Current issues:
- Using console.log for errors, info, and debugging
- No structured logging
- No log levels

**Quick fix for now**: Leave as is but plan to implement proper logging post-launch

### 10. Complete TODO Items in Code
**Why**: Incomplete features may cause errors
**Time**: 1 hour

Found TODOs:
1. `src/backend/utils/audioUtils.ts:14` - Audio duration calculation
2. `src/components/debate/CrossfireRealtimePanel.tsx:68` - Audio recording implementation

**Action**: These are non-critical, can be addressed post-launch

## ðŸŸ¢ NICE TO HAVE - Post-Launch Improvements

### 11. Performance Optimizations
- Implement Redis for rate limiting (currently in-memory)
- Add CDN for static assets
- Enable Vercel Edge Functions where appropriate
- Optimize OpenTelemetry (currently heavy instrumentation)

### 12. Code Quality Improvements
- Fix remaining 229 ESLint errors (mostly type annotations)
- Remove temp directories (`src/temp-debatetest2-refactor`)
- Standardize module system (currently mixed CommonJS/ESM)
- Implement structured logging to replace console.log

### 13. Enhanced Features
- User management dashboard
- Analytics dashboard  
- Content moderation tools
- Email notifications
- Export debate transcripts
- Team/organization support

## ðŸ“‹ Pre-Deployment Checklist

**Must complete before deploying**:
- [ ] All database tables created (Step 1)
- [ ] All environment variables set (Step 2)
- [ ] Audio bucket created (Step 3)
- [ ] CORS security fixed (Step 4)
- [ ] Run `npm run build` - must pass
- [ ] Run `npm run typecheck` - must pass
- [ ] Test core features locally:
  - [ ] User registration/login
  - [ ] Create a debate
  - [ ] Upload a document
  - [ ] Search (after DB fix)
  - [ ] Speech feedback

**In Vercel Dashboard**:
- [ ] Set all environment variables
- [ ] Verify domain is configured
- [ ] Enable Vercel Analytics (optional)

## ðŸš¦ Current Project Status

- âœ… **Working**: Auth, speech feedback, basic UI
- âœ… **Fixed by AI**: TypeScript errors, rate limiting, REST fallbacks
- âŒ **Broken**: Search (needs DB), debates (needs DB + agent ID), feedback (needs DB)
- âš ï¸ **Security Issues**: CORS needs fixing
- âš ï¸ **Configuration**: Port inconsistency, multiple configs

**Overall**: ~65% production ready (was 60% before AI fixes)

## ðŸŽ¯ Recommended Order of Operations

1. **Database fixes** (1 hour) - Nothing works without this
2. **Environment variables** (20 min) - Critical for features
3. **Audio bucket** (5 min) - Quick fix
4. **Security fixes** (15 min) - Important for production
5. **Deploy to staging** - Test everything
6. **Configuration cleanup** (30 min) - Before final deploy
7. **Deploy to production**
8. **Set up monitoring** (30 min) - After deploy

## ðŸ’¡ Quick Reference Commands

```bash
# After database fixes
npm run build
npm run typecheck
npm run lint

# Test locally
npm run dev

# Create audio bucket
node scripts/setup-debate-audio-bucket.js

# Deploy
vercel --prod
```

## âš ï¸ Common Pitfalls to Avoid

1. **Don't forget to clear Supabase cache** after creating tables
2. **Don't deploy with ENABLE_SQL_ENDPOINT=true**
3. **Don't use wildcard CORS in production**
4. **Don't skip setting ELEVENLABS_CROSSFIRE_AGENT_ID** - debates won't work
5. **Test everything locally first** - deployment debugging is harder

---

**Last Updated**: By AI after comprehensive analysis
**Total Tasks**: 13 major items (4 critical, 6 important, 3 nice-to-have)
**Estimated Time**: 3-4 hours for critical + important items